{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 17:31:42.205851: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 17:31:45.006512: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-15 17:31:45.006589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-15 17:31:45.410094: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-15 17:31:46.169201: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 17:31:46.170291: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 17:31:50.749179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "# Getting the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Appending the data/mnist.npz to the previous path to get the full path\n",
    "data_path = os.path.join(current_dir, \"/workspaces/Portfolio/Machine Learning/C1/W3/mnist.npz\")\n",
    "# Discarding the test set\n",
    "(training_images, training_labels) , _  = tf.keras.datasets.mnist.load_data(path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: reshape and normalize\n",
    "\n",
    "def reshape_and_normalize(images):\n",
    "    #Reshape the images to add an extra dimension\n",
    "    images = images.reshape((-1, 28, 28, 1))\n",
    "\n",
    "    # Normalize the pixel values\n",
    "    images = images /255.0\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
      "\n",
      "Shape of one image after reshaping: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# reloading the images in case you run this cell multiple times\n",
    "(training_images, training_labels) , _  = tf.keras.datasets.mnist.load_data(path=data_path)\n",
    "\n",
    "# applying the function\n",
    "training_images = reshape_and_normalize(training_images)\n",
    "\n",
    "print(f'Maximum pixel value after normalization: {np.max(training_images)}\\n')\n",
    "print(f'Shape of training set after reshaping: {training_images.shape}\\n')\n",
    "print(f'Shape of one image after reshaping: {training_images[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') > 0.995):\n",
    "            print(\"\\n Reached 99.5% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional_model\n",
    "def convolutional_model():\n",
    "\n",
    "    #Defining the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10,activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss = 'sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1232 - accuracy: 0.9630\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0400 - accuracy: 0.9880\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0253 - accuracy: 0.9921\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0181 - accuracy: 0.9943\n",
      "Epoch 5/10\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9956\n",
      " Reached 99.5% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0131 - accuracy: 0.9956\n"
     ]
    }
   ],
   "source": [
    "model = convolutional_model()\n",
    "\n",
    "#Get number of weights\n",
    "model_params = model.count_params()\n",
    "\n",
    "assert model_params < 1000000, (\n",
    "    f'Your model has {model_params:,}params. For successful graidng, please keep it'\n",
    "    f'under 1,000,000 by reducing the number of units in your Conv2D and Dense layers.'\n",
    ")\n",
    "\n",
    "# Instantiate callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
